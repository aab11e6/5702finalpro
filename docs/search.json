[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Insurance Claims",
    "section": "",
    "text": "1 Introduction\nInsurance fraud, a prevalent and complex issue in the insurance industry, presents as a multifaceted challenge with far-reaching consequences. At its core, insurance fraud involves the intentional deception or misrepresentation in an insurance process, aiming to secure unlawful gain. This phenomenon is not just a concern for insurance companies; it significantly impacts honest customers and the industry as a whole.\nThe complexity of insurance fraud lies in its diverse manifestations. It isn’t confined to a single pattern or method; rather, it spans a spectrum of activities ranging from exaggerated claims to the fabrication of accidents or damages. This diversity makes it a particularly challenging problem to address. Its impacts are substantial and varied, leading to considerable financial losses for insurance providers. These losses, in turn, often translate to increased premiums for honest policyholders, who unwittingly bear the cost of fraudulent activities.\nFurthermore, insurance fraud is not driven by a single factor. It is influenced by a myriad of elements such as economic conditions, the intricacies of insurance policies, individual motivations, and opportunities to exploit system vulnerabilities. This interplay of factors contributes to the complexity of detecting and preventing fraud, requiring a nuanced and multifaceted approach.\nAll in all, understanding and addressing insurance fraud is crucial for maintaining the integrity and sustainability of the insurance sector. It is not just about mitigating financial losses but also about ensuring fairness and trustworthiness in a system that millions rely on for risk management and security."
  },
  {
    "objectID": "index.html#rationale-for-topic-selection",
    "href": "index.html#rationale-for-topic-selection",
    "title": "Insurance Claims",
    "section": "1.1 Rationale for Topic Selection",
    "text": "1.1 Rationale for Topic Selection\nIn choosing the topic ‘Multifaceted Analysis of Insurance Fraud,’ our intent is to delve deeply into the intricate and often interconnected factors that give rise to insurance fraud. This complexity is not just a mere academic interest; it is central to the real-world challenge of detecting and preventing fraudulent activities in the insurance sector. We are particularly drawn to the multifaceted nature of this issue – it is not driven by singular causes but is a tapestry woven from various threads including geographical influences, the specifics of insurance policies, the characteristics of those insured, the nature of the incidents, and the details of the vehicles involved.\nUnderstanding this interplay is not merely an exercise in data analysis; it’s about peeling back the layers to reveal how these diverse factors come together to create an environment where fraud can occur. Through our analysis, we aim to provide a comprehensive view of these elements, exploring how they individually and collectively contribute to the occurrence of fraudulent claims. This is crucial because effectively combating insurance fraud requires a holistic approach. By identifying patterns and correlations, we can better understand where vulnerabilities lie and, therefore, where interventions can be most effectively targeted.\nMoreover, our interest in this topic is fueled by the significant real-world implications of insurance fraud. It’s not just about financial losses to insurance companies; it’s about the broader impact on policyholders and the insurance industry as a whole. The ripple effects of fraud can be seen in increased premiums for honest customers and a potential loss of trust in the insurance system. By unraveling these complex relationships, our study seeks to contribute valuable insights that could aid in the development of more sophisticated and effective fraud detection and prevention strategies. Ultimately, the goal is to foster a more secure and trustworthy insurance landscape for all stakeholders."
  },
  {
    "objectID": "index.html#research-questions-and-areas-of-focus",
    "href": "index.html#research-questions-and-areas-of-focus",
    "title": "Insurance Claims",
    "section": "1.2 Research Questions and Areas of Focus",
    "text": "1.2 Research Questions and Areas of Focus\nIn embarking on this study, our aim is to dissect the multifaceted nature of insurance fraud through a series of focused research questions. These questions are designed not only to deepen our understanding of the phenomenon but also to uncover potential avenues for more effective fraud prevention strategies. The areas of focus that we have identified are pivotal in shaping the landscape of insurance fraud and include geographical trends, policy features, insured demographics, incident characteristics, and vehicle information.\nGeographical Trends: our first area of inquiry centers on the impact of geographical trends on insurance fraud. We are curious to explore whether certain regions or states exhibit higher incidences of fraudulent claims. Are there socio-economic or legislative factors in these regions that might contribute to this trend? Understanding geographical patterns can provide valuable insights into targeted fraud prevention measures.\nPolicy Features: Next, we aim to investigate the role of policy features in the likelihood of fraudulent claims. Do higher deductibles or specific types of coverage correlate with a higher incidence of fraud? This line of questioning seeks to understand how the structure and terms of insurance policies might inadvertently encourage or deter fraudulent activities.\nDemographic Characteristics: Another crucial aspect of our study is to examine whether specific demographic characteristics are more frequently associated with fraud. Does age, gender, education level, or occupation of the insured play a role in the propensity to commit insurance fraud? This exploration could highlight vulnerable segments or risk factors in policy underwriting.\nIncident Details: The nature of the incident itself is also a significant factor. We are interested in exploring how the details of the incident, such as its severity or type, correlate with the likelihood of a claim being fraudulent. For instance, are minor incidents more likely to be exaggerated, or do severe incidents have a higher likelihood of fraud?\nVehicle Information: Lastly, the type or model of the vehicle involved in the insurance claim might also influence the incidence of fraud. Are luxury vehicles more associated with fraudulent claims, or are there specific models or years that seem to be more prone to fraud?\nThrough these questions, we hope to uncover patterns and correlations that can aid in the development of more effective fraud detection tools and policies. This study is not just about identifying the ‘what’ of insurance fraud; it’s about understanding the ‘why’ and ‘how,’ which are crucial for any meaningful intervention in this area."
  },
  {
    "objectID": "index.html#background-context",
    "href": "index.html#background-context",
    "title": "Insurance Claims",
    "section": "1.3 Background Context",
    "text": "1.3 Background Context\nFor readers who may be new to the subject, it’s crucial to understand why a study on insurance fraud is not only relevant but essential. Insurance fraud, often perceived as a victimless crime, in fact, has far-reaching implications that extend beyond the insurance industry, affecting policyholders, insurance companies, and the broader economy.\nFirstly, for insurance companies, fraud represents a significant financial drain. The costs incurred due to fraudulent claims directly impact their bottom line. These costs are not just absorbed by the companies; they are typically passed on to policyholders in the form of higher premiums. Therefore, insurance fraud indirectly taxes honest customers, increasing their financial burden.\nBeyond the financial aspect, insurance fraud undermines the trust in the insurance system. When fraud becomes prevalent, it can lead to stricter claim scrutiny, potentially causing delays and added complications for genuine claimants. This erodes the foundational trust that policyholders place in their insurance providers – the assurance that in times of need, their claims will be handled fairly and efficiently.\nThe broader economic impact is also significant. High levels of insurance fraud can lead to increased costs for goods and services. For example, in the case of auto insurance fraud, increased premiums can elevate the operational costs for businesses relying on transportation, which may then be passed on to consumers.\nUnderstanding the various factors that influence insurance fraud is pivotal in developing effective mitigation strategies. By identifying and analyzing the trends, patterns, and correlations within this complex issue, stakeholders can tailor their approaches to combating fraud more effectively. This could include more sophisticated risk assessment models, targeted educational campaigns, and enhanced investigative practices.\nIn essence, this study aims to shed light on the intricate dynamics of insurance fraud, providing insights that could lead to more robust prevention and detection measures. Such efforts are vital in safeguarding the financial health of the insurance industry, protecting consumers from undue costs, and maintaining the integrity of the insurance process."
  },
  {
    "objectID": "index.html#objective",
    "href": "index.html#objective",
    "title": "Insurance Claims",
    "section": "1.4 Objective",
    "text": "1.4 Objective\nThe primary objective of this study is to dissect and analyze the intricate relationships between various factors that lead to insurance fraud. By delving into aspects such as geographical trends, policy features, demographic characteristics of the insured, the nature of the incidents, and vehicle-related information, the study aims to provide a comprehensive understanding of how these elements interplay and contribute to fraudulent activities in the insurance sector.\nThis analysis is not just an academic exercise; it is instrumental in shaping the future of insurance policies and fraud detection methods. Through a thorough examination of these multifaceted factors, the study seeks to identify key indicators and patterns of fraud, which can be leveraged to enhance the accuracy and efficiency of fraud detection. By pinpointing specific areas where fraud is more prevalent or identifying particular characteristics that are often associated with fraudulent claims, insurance companies can refine their risk assessment models and develop more targeted prevention strategies.\nFurthermore, the insights gained from this study have the potential to inform the development of more sophisticated policy structures and underwriting processes. This can lead to more balanced and fair pricing of insurance premiums, ensuring that honest policyholders are not unduly burdened by the costs associated with fraudulent activities.\nIn essence, the goal of this study is to contribute to the creation of a more secure, fair, and trustworthy insurance environment. By improving our understanding of the complexities surrounding insurance fraud, we can pave the way for more effective industry practices, ultimately benefiting insurance companies, policyholders, and the broader economy alike."
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "2.1 Description",
    "text": "2.1 Description\nThe data is in .csv format. There are 1,000 rows with 40 columns, however, the column “_c39” is all null so we will drop it before our analysis.\nThere are 38 attributes (features) in total in the data. They can be divided into five main categories, which are Personal and Policy Information, Location and Vehicle Information, Incident Details, Claim Information and Other Attributes:\n\nPersonal and Policy Information: It contains columns for customer characteristics such as months_as_customer, age, policy_number, policy_bind_date, policy_state, policy_csl (Combined Single Limit), policy_deductable, policy_annual_premium, and umbrella_limit.\nLocation and Vehicle Information: There are details about the insured_zip, incident_location, incident_hour_of_the_day, as well as information about the vehicle involved like auto_make, auto_model, and auto_year.\nIncident Details: The dataset includes specific details about incidents such as incident_date, incident_type, collision_type, incident_severity, authorities_contacted, and whether a police_report_available.\nClaim Information: This encompasses the total_claim_amount, injury_claim, property_claim, vehicle_claim, and whether the claim was reported as fraud (fraud_reported).\nOther Attributes: Additional attributes include details about the insured like insured_sex, insured_education_level, insured_occupation, insured_hobbies, insured_relationship, as well as information about witnesses, bodily injuries, and other aspects related to the insurance claims.\n\nBelow is what our data looks like:\n\n\nCode\ndata &lt;- read.csv('insurance_claims.csv', na.strings = c(\"?\", \"NA\"))\nhead(data)\n\n\n  months_as_customer age policy_number policy_bind_date policy_state policy_csl\n1                328  48        521585       2014-10-17           OH    250/500\n2                228  42        342868       2006-06-27           IN    250/500\n3                134  29        687698       2000-09-06           OH    100/300\n4                256  41        227811       1990-05-25           IL    250/500\n5                228  44        367455       2014-06-06           IL   500/1000\n6                256  39        104594       2006-10-12           OH    250/500\n  policy_deductable policy_annual_premium umbrella_limit insured_zip\n1              1000               1406.91              0      466132\n2              2000               1197.22        5000000      468176\n3              2000               1413.14        5000000      430632\n4              2000               1415.74        6000000      608117\n5              1000               1583.91        6000000      610706\n6              1000               1351.10              0      478456\n  insured_sex insured_education_level insured_occupation insured_hobbies\n1        MALE                      MD       craft-repair        sleeping\n2        MALE                      MD  machine-op-inspct         reading\n3      FEMALE                     PhD              sales     board-games\n4      FEMALE                     PhD       armed-forces     board-games\n5        MALE               Associate              sales     board-games\n6      FEMALE                     PhD       tech-support  bungie-jumping\n  insured_relationship capital.gains capital.loss incident_date\n1              husband         53300            0    2015-01-25\n2       other-relative             0            0    2015-01-21\n3            own-child         35100            0    2015-02-22\n4            unmarried         48900       -62400    2015-01-10\n5            unmarried         66000       -46000    2015-02-17\n6            unmarried             0            0    2015-01-02\n             incident_type  collision_type incident_severity\n1 Single Vehicle Collision  Side Collision      Major Damage\n2            Vehicle Theft            &lt;NA&gt;      Minor Damage\n3  Multi-vehicle Collision  Rear Collision      Minor Damage\n4 Single Vehicle Collision Front Collision      Major Damage\n5            Vehicle Theft            &lt;NA&gt;      Minor Damage\n6  Multi-vehicle Collision  Rear Collision      Major Damage\n  authorities_contacted incident_state incident_city  incident_location\n1                Police             SC      Columbus     9935 4th Drive\n2                Police             VA     Riverwood       6608 MLK Hwy\n3                Police             NY      Columbus  7121 Francis Lane\n4                Police             OH     Arlington   6956 Maple Drive\n5                  None             NY     Arlington       3041 3rd Ave\n6                  Fire             SC     Arlington 8973 Washington St\n  incident_hour_of_the_day number_of_vehicles_involved property_damage\n1                        5                           1             YES\n2                        8                           1            &lt;NA&gt;\n3                        7                           3              NO\n4                        5                           1            &lt;NA&gt;\n5                       20                           1              NO\n6                       19                           3              NO\n  bodily_injuries witnesses police_report_available total_claim_amount\n1               1         2                     YES              71610\n2               0         0                    &lt;NA&gt;               5070\n3               2         3                      NO              34650\n4               1         2                      NO              63400\n5               0         1                      NO               6500\n6               0         2                      NO              64100\n  injury_claim property_claim vehicle_claim auto_make auto_model auto_year\n1         6510          13020         52080      Saab        92x      2004\n2          780            780          3510  Mercedes       E400      2007\n3         7700           3850         23100     Dodge        RAM      2007\n4         6340           6340         50720 Chevrolet      Tahoe      2014\n5         1300            650          4550    Accura        RSX      2009\n6         6410           6410         51280      Saab         95      2003\n  fraud_reported X_c39\n1              Y    NA\n2              Y    NA\n3              N    NA\n4              Y    NA\n5              N    NA\n6              Y    NA"
  },
  {
    "objectID": "data.html#research-plan",
    "href": "data.html#research-plan",
    "title": "2  Data",
    "section": "2.2 Research plan",
    "text": "2.2 Research plan\nOur project will initially focus on an exploratory analysis of each category of data in the dataset, aiming to unearth potential connections among them and their relationship with insurance fraud. Then we will employ techniques such as regression analysis and Principal Component Analysis (PCA). These methods will enable us to compare and quantify the impact of different factors on the likelihood of fraud.\nBy conducting this multi-dimensional analysis, we will leverage the dataset’s comprehensive range of data - encompassing geographical trends, policy features, demographic characteristics, incident specifics, and vehicle information. This approach will not only help us identify patterns and insights in each data category but also allow us to understand the cumulative impact of these factors on insurance fraud."
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.3 Missing value analysis",
    "text": "2.3 Missing value analysis\nIn this dataset, all the missing data are represented by “?” elements, so we need to replace all “?” elements with null values. Besides, there is one column named “_c39” with all null values that can be dropped.\n\n\nCode\ndata &lt;- read.csv('insurance_claims.csv', na.strings = c(\"?\", \"NA\"))\ndata &lt;- subset(data, select = -X_c39)\n\n\nThen calculate the number of missing values in each column and visualize the missing data using a bar plot for an overview.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\n# Count missing values\nmissing_values &lt;- sapply(data, function(x) sum(is.na(x)))\nmissing_data_frame &lt;- data.frame(column = names(missing_values), missing_count = missing_values)\n\n# Create a data frame for plotting\nmissing_data_frame &lt;- data.frame(column = names(missing_values), missing_count = missing_values)\n\n# Create the bar plot with ggplot2\nggplot(missing_data_frame |&gt; arrange(desc(missing_count)), aes(x = reorder(column, missing_count), y = missing_count)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +  # Reverse the coordinate system\n  xlab(\"Column\") +\n  ylab(\"Number of Missing Values\") +\n  ggtitle(\"Missing Values per Column\") # Add titles and labels as needed\n\n\n\n\n\nObviously, there are only three columns with missing values, so we proceed to drop all the other columns and use plot_missing in redav to plot the them.\n\n\nCode\nlibrary(redav)\nplot_missing(subset(data, select = c(\"police_report_available\",\"property_damage\",\"collision_type\")), percent = FALSE)\n\n\n\n\n\nThe patterns indicated by these plots suggest that the missing data is mostly concentrated in a single variable which is illstrated by the fact that case 2 and 3 in missing pattern are significantly more than other cases. Missingness spreading across several variables needs to be handled carefully, as it could bias the results of any analysis performed on the dataset. Techniques such as imputation or the use of models that can handle missing data might be necessary to account for the missing values."
  },
  {
    "objectID": "results.html#section",
    "href": "results.html#section",
    "title": "3  Results",
    "section": "3.1 1",
    "text": "3.1 1"
  },
  {
    "objectID": "results.html#geographical-trends",
    "href": "results.html#geographical-trends",
    "title": "3  Results",
    "section": "3.1 Geographical Trends",
    "text": "3.1 Geographical Trends\nHere, we primarily focus on two variables: ‘policy_state,’ which means the state where the insurance policy was issued; and ‘incident_state,’ which means the state where the incident occurred.\n\n\nCode\n# 将 'fraud_reported' 转换为数值\ndata$fraud_reported_numeric &lt;- ifelse(data$fraud_reported == \"Y\", 1, 0)\n\n# 按 'incident_state' 分组并计算欺诈率\nfraud_rate_by_state &lt;- aggregate(fraud_reported_numeric ~ incident_state, data, mean)\n\n# 将欺诈率转换为百分比\nfraud_rate_by_state$fraud_rate &lt;- fraud_rate_by_state$fraud_reported_numeric * 100\n\n# 移除不再需要的列\nfraud_rate_by_state$fraud_reported_numeric &lt;- NULL\n\n# 创建州名缩写与全称对应的映射\nstate_abbreviations &lt;- c(\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n                         \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n                         \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n                         \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n                         \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\")\nstate_names &lt;- c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\",\n                 \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\",\n                 \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\",\n                 \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\",\n                 \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\",\n                 \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\",\n                 \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\",\n                 \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\",\n                 \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\")\n\nstate_map &lt;- setNames(state_names, state_abbreviations)\n\n# 转换 'incident_state' 列中的缩写为全称\nfraud_rate_by_state$incident_state &lt;- tolower(state_map[fraud_rate_by_state$incident_state])\n\n# 重命名列\nnames(fraud_rate_by_state) &lt;- c(\"region\", \"value\")\n\n\n\n\nCode\nlibrary(choroplethr)\nlibrary(ggplot2)\nlibrary(RColorBrewer)\n\n# 创建州级地图并更改颜色方案\nmap &lt;- state_choropleth(fraud_rate_by_state, \n                        title = \"Fraud Rate by State\", \n                        legend = \"Fraud Rate\") +\n       scale_fill_brewer(palette = \"Reds\", name = \"Fraud Rate\")\n\n\nWarning in self$bind(): The following regions were missing and are being set to\nNA: arizona, arkansas, louisiana, minnesota, mississippi, montana, new mexico,\nnorth dakota, oklahoma, tennessee, california, delaware, wisconsin, wyoming,\nalabama, alaska, florida, idaho, kansas, maryland, colorado, new jersey,\nwashington, vermont, utah, iowa, kentucky, maine, massachusetts, connecticut,\nmichigan, missouri, nebraska, nevada, new hampshire, oregon, rhode island, south\ndakota, district of columbia, texas, georgia, hawaii, illinois, indiana\n\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\nCode\n# 调整地图的显示范围以仅包括特定州\n# 这里的数值是示例，您可能需要根据需要进行调整\nmap + coord_fixed(xlim = c(-85, -70), ylim = c(30, 45))\n\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n\n\n\n\n\n\n\nCode\n# 将 'fraud_reported' 转换为数值\ndata$fraud_reported_numeric &lt;- ifelse(data$fraud_reported == \"Y\", 1, 0)\n\n# 按 'incident_state' 分组并计算欺诈率\nfraud_rate_by_state &lt;- aggregate(fraud_reported_numeric ~ policy_state, data, mean)\n\n# 将欺诈率转换为百分比\nfraud_rate_by_state$fraud_rate &lt;- fraud_rate_by_state$fraud_reported_numeric * 100\n\n# 移除不再需要的列\nfraud_rate_by_state$fraud_reported_numeric &lt;- NULL\n\n# 转换 'incident_state' 列中的缩写为全称\nfraud_rate_by_state$policy_state &lt;- tolower(state_map[fraud_rate_by_state$policy_state])\n\n# 重命名列\nnames(fraud_rate_by_state) &lt;- c(\"region\", \"value\")\n\n# 创建州级地图并更改颜色方案\nmap &lt;- state_choropleth(fraud_rate_by_state, \n                        title = \"Fraud Rate by State\", \n                        legend = \"Fraud Rate\") +\n       scale_fill_brewer(palette = \"Reds\", name = \"Fraud Rate\")\n\n\nWarning in min(xx[xx &gt; upper]): no non-missing arguments to min; returning Inf\n\n\nWarning in self$bind(): The following regions were missing and are being set to\nNA: arizona, arkansas, louisiana, minnesota, mississippi, montana, new mexico,\nnorth dakota, oklahoma, pennsylvania, tennessee, virginia, california, delaware,\nwest virginia, wisconsin, wyoming, alabama, alaska, florida, idaho, kansas,\nmaryland, colorado, new jersey, north carolina, south carolina, washington,\nvermont, utah, iowa, kentucky, maine, massachusetts, connecticut, michigan,\nmissouri, nebraska, nevada, new hampshire, new york, oregon, rhode island, south\ndakota, district of columbia, texas, georgia, hawaii\n\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\nCode\n# 调整地图的显示范围以仅包括特定州\n# 这里的数值是示例，您可能需要根据需要进行调整\nmap + coord_fixed(xlim = c(-95, -80), ylim = c(36, 45))\n\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n\n\n\n\n\n\n\nCode\nlibrary(ggalluvial)\n\n\nWarning: package 'ggalluvial' was built under R version 4.2.3\n\n\nCode\nlibrary(alluvial)\n\n\nWarning: package 'alluvial' was built under R version 4.2.3\n\n\nCode\nselected_data &lt;- data %&gt;% \n  select(policy_state, incident_state, fraud_reported)\n\n# 计算每种组合的频率\nfrequency_data &lt;- selected_data %&gt;% \n  count(policy_state, incident_state, fraud_reported)\n\n# 创建流图\nggplot(data = frequency_data, \n       aes(axis1 = policy_state, axis2 = incident_state, axis3 = fraud_reported, y = n)) +\n  geom_alluvium(aes(fill = fraud_reported)) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  scale_x_discrete(limits = c(\"Policy State\", \"Incident State\", \"Fraud Reported\")) + # 改变横坐标名称\n  theme_minimal() +\n  theme(\n    axis.title.y = element_blank(), # 删除 y 轴标题\n    axis.text.y = element_blank(), # 删除 y 轴文本\n    axis.ticks.y = element_blank(), # 删除 y 轴刻度\n    panel.border = element_blank(), # 删除边框\n    panel.grid.major = element_blank(), # 删除主要网格线\n    panel.grid.minor = element_blank() # 删除次要网格线\n  ) +\n  labs(title = \"Relationships among Policy State, Incident State, and Fraud Reported\",\n       x = \"\") # 删除 x 轴标题\n\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\n\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\n\n\n\n\n\n没什么规律，五湖四海呈现相同特征"
  },
  {
    "objectID": "results.html#incident-details",
    "href": "results.html#incident-details",
    "title": "3  Results",
    "section": "3.2 Incident Details",
    "text": "3.2 Incident Details\n\n3.2.1 capital situation\nwe mainly focus on two variables: ‘capital-gains,’ which means the capital gains of the insured individual; and ‘capital-loss,’ which means the capital losses of the insured individual.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\n# 假设 data 是您的原始数据集\n# 添加一列作为个体或分组的标识符\ndata &lt;- data %&gt;%\n  mutate(id = row_number())\n\n# 为了绘制斜率图，我们需要将数据转换为长格式\nlong_data &lt;- data %&gt;%\n  select(id, capital.loss, capital.gains) %&gt;%\n  pivot_longer(cols = -id, names_to = \"variable\", values_to = \"value\")\n\n# 绘制斜率图，为每个 id 绘制一条线\nggplot(long_data, aes(x = variable, y = value, group = id)) +\n  geom_line(alpha = 0.06) +\n  theme_minimal() +\n  labs(title = \"Slope Graph for Capital Loss and Capital Gain\",\n       x = \"\",\n       y = \"Value\")\n\n\n\n\n\n\n\n3.2.2 Time\nHere, we mainly focus on two variables: ‘incident_date,’ which means the date of the incident; and ‘incident_hour_of_the_day,’ which means the hour of the day when the incident occurred.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(lubridate)\n\n\nWarning: package 'lubridate' was built under R version 4.2.3\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nCode\n# 转换 incident_date 到 Date 类型\ndata$incident_date &lt;- as.Date(data$incident_date, format = \"%m/%d/%Y\")\n\n# 标记欺诈的事件\ndata$fraud_flag &lt;- ifelse(data$fraud_reported == 'Y', 1, 0)\n\n# 计算每个日期的欺诈率\nfraud_rate_by_date &lt;- data %&gt;%\n  group_by(incident_date) %&gt;%\n  summarise(fraud_rate = mean(fraud_flag))\n\n# 绘制密度图\nggplot(fraud_rate_by_date, aes(x = incident_date, y = fraud_rate * 100)) +\n  geom_smooth(method = \"loess\", se = FALSE, span = 0.3) + \n  theme_minimal() +\n  labs(title = \"Fraud Rate by Incident Date\",\n       x = \"Incident Date\",\n       y = \"Fraud Rate(%)\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nCode\n# 计算每个小时的欺诈率\nfraud_rate_by_hour &lt;- data %&gt;%\n  group_by(incident_hour_of_the_day) %&gt;%\n  summarise(fraud_rate = mean(fraud_flag) * 100)  # 转换为百分比\n\n# 绘制欺诈率随小时变化的图\nggplot(fraud_rate_by_hour, aes(x = incident_hour_of_the_day, y = fraud_rate)) +\n  geom_smooth(method = \"loess\", se = FALSE, span = 0.3) +  # 添加平滑趋势线\n  theme_minimal() +\n  labs(title = \"Fraud Rate by Incident Hour of the Day\",\n       x = \"Incident Hour of the Day\",\n       y = \"Fraud Rate(%)\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n3.2.3 Type\nFocus on three variables: ‘incident_type,’ which is the type of the incident; ‘collision_type,’ which is the type of collision, if applicable; and ‘incident_severity,’ which is the severity of the incident.\n\n\nCode\ndata1 &lt;- subset(data, !is.na(incident_type) & !is.na(collision_type) & !is.na(incident_severity) & !is.na(fraud_reported))\n\nvcd::mosaic(fraud_reported ~ incident_type + collision_type + incident_severity, data1, direction = c('h', 'h', 'v'), main = \"Association between Age.Groups and Subchapter\")\n\n\n\n\n\n\n\nCode\nselected_data &lt;- data1 %&gt;% \n  select(incident_type, collision_type, incident_severity, fraud_reported)\n\n# 计算每种组合的频率\nfrequency_data &lt;- selected_data %&gt;% \n  count(incident_type, collision_type, incident_severity, fraud_reported)\n\n# 创建流图\nggplot(data = frequency_data, \n       aes(axis1 = incident_type, axis2 = collision_type, axis3 = incident_severity, axis4 = fraud_reported, y = n)) +\n  geom_alluvium(aes(fill = fraud_reported)) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  scale_x_discrete(limits = c(\"incident_type\", \"collision_type\", \"incident_severity\", \"fraud_reported\")) + # 改变横坐标名称\n  theme_minimal() +\n  theme(\n    axis.title.y = element_blank(), # 删除 y 轴标题\n    axis.text.y = element_blank(), # 删除 y 轴文本\n    axis.ticks.y = element_blank(), # 删除 y 轴刻度\n    panel.border = element_blank(), # 删除边框\n    panel.grid.major = element_blank(), # 删除主要网格线\n    panel.grid.minor = element_blank() # 删除次要网格线\n  ) +\n  labs(title = \"Relationships among Policy State, Incident State, and Fraud Reported\",\n       x = \"\") # 删除 x 轴标题\n\n\n\n\n\n\n\n3.2.4 damage and trustworthiness\nThis time we focus on four variables to explore their relationship with fraud: ‘property_damage’, which indicates if there was any property damage; ‘bodily_injuries’, the number of bodily injuries in the incident; ‘police_report_available’, which indicates if a police report is available; and ‘witnesses’, the number of witnesses to the incident.\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Assuming your data is already read and named 'data'\n# Convert the fraud_reported to a numerical flag\n\ndata1 &lt;- subset(data, !is.na(property_damage) & !is.na(bodily_injuries))\n\ndata1$fraud_reported_flag &lt;- ifelse(data1$fraud_reported == \"Y\", 1, 0)\n\n# Group by 'property_damage' and 'bodily_injuries' to calculate the mean fraud rate\nfraud_rates &lt;- data1 %&gt;%\n  group_by(property_damage, bodily_injuries) %&gt;%\n  summarise(fraud_rate = mean(fraud_reported_flag, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\n`summarise()` has grouped output by 'property_damage'. You can override using\nthe `.groups` argument.\n\n\nCode\n# Create the heatmap\np1 &lt;- ggplot(fraud_rates, aes(x = property_damage, y = bodily_injuries, fill = fraud_rate)) +\n  geom_tile() + \n  scale_fill_gradient(low = \"white\", high = \"red\", labels = scales::percent_format()) +\n  theme_minimal() +\n  labs(x = \"Bodily Injuries\", y = \"Property Damage\", fill = \"Fraud Rate\") +\n  geom_text(aes(label = scales::percent(fraud_rate)), size = 4, colour = \"black\")\n\n\n\n\nCode\nlibrary(patchwork)\n\n\nWarning: package 'patchwork' was built under R version 4.2.3\n\n\nCode\ndata2 &lt;- subset(data, !is.na(police_report_available) & !is.na(witnesses))\n\ndata2$fraud_reported_flag &lt;- ifelse(data2$fraud_reported == \"Y\", 1, 0)\n\n# Group by 'property_damage' and 'bodily_injuries' to calculate the mean fraud rate\nfraud_rates &lt;- data2 %&gt;%\n  group_by(police_report_available, witnesses) %&gt;%\n  summarise(fraud_rate = mean(fraud_reported_flag, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\n`summarise()` has grouped output by 'police_report_available'. You can override\nusing the `.groups` argument.\n\n\nCode\n# Create the heatmap\np2 &lt;- ggplot(fraud_rates, aes(x = police_report_available, y = witnesses, fill = fraud_rate)) +\n  geom_tile() + \n  scale_fill_gradient(low = \"white\", high = \"red\", labels = scales::percent_format()) +\n  theme_minimal() +\n  labs(x = \"police_report_available\", y = \"witnesses\", fill = \"Fraud Rate\") +\n  geom_text(aes(label = scales::percent(fraud_rate)), size = 4, colour = \"black\")\n\n(p1 | p2)\n\n\n\n\n\n\n\n3.2.5 Claim\nThis time, we are primarily focusing on four numerical variables: total claim amount (total_claim_amount), claim amount for injuries (injury_claim), claim amount for property damage (property_claim), and claim amount for vehicle damage (vehicle_claim).\n\n\nCode\nlibrary(ggplot2)\n\n# 绘制盒形图，使用facet_wrap来根据fraud_reported的值分面\np1 &lt;- ggplot(data, aes(x = total_claim_amount, y = fraud_reported)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(x = \"Total Claim Amount\", y = \"Fraud Reported\", title = \"Total Claim Amount by Fraud Reported\")\n\np2 &lt;- ggplot(data, aes(x = injury_claim, y = fraud_reported)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(x = \"claim amount for injuries\", y = \"Fraud Reported\", title = \"Total Claim Amount by Fraud Reported\")\n\np3 &lt;- ggplot(data, aes(x = property_claim, y = fraud_reported)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(x = \"claim amount for property damage\", y = \"Fraud Reported\", title = \"Total Claim Amount by Fraud Reported\")\n\np4 &lt;- ggplot(data, aes(x = vehicle_claim, y = fraud_reported)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(x = \"claim amount for vehicle damage\", y = \"Fraud Reported\", title = \"Total Claim Amount by Fraud Reported\")\n\n(p1 | p2) /\n(p3 | p4)"
  }
]