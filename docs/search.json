[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Insurance Claims",
    "section": "",
    "text": "1 Introduction\nInsurance fraud, a prevalent and complex issue in the insurance industry, presents as a multifaceted challenge with far-reaching consequences. At its core, insurance fraud involves the intentional deception or misrepresentation in an insurance process, aiming to secure unlawful gain. This phenomenon is not just a concern for insurance companies; it significantly impacts honest customers and the industry as a whole.\nThe complexity of insurance fraud lies in its diverse manifestations. It isn’t confined to a single pattern or method; rather, it spans a spectrum of activities ranging from exaggerated claims to the fabrication of accidents or damages. This diversity makes it a particularly challenging problem to address. Its impacts are substantial and varied, leading to considerable financial losses for insurance providers. These losses, in turn, often translate to increased premiums for honest policyholders, who unwittingly bear the cost of fraudulent activities.\nFurthermore, insurance fraud is not driven by a single factor. It is influenced by a myriad of elements such as economic conditions, the intricacies of insurance policies, individual motivations, and opportunities to exploit system vulnerabilities. This interplay of factors contributes to the complexity of detecting and preventing fraud, requiring a nuanced and multifaceted approach.\nAll in all, understanding and addressing insurance fraud is crucial for maintaining the integrity and sustainability of the insurance sector. It is not just about mitigating financial losses but also about ensuring fairness and trustworthiness in a system that millions rely on for risk management and security."
  },
  {
    "objectID": "index.html#rationale-for-topic-selection",
    "href": "index.html#rationale-for-topic-selection",
    "title": "Insurance Claims",
    "section": "1.1 Rationale for Topic Selection",
    "text": "1.1 Rationale for Topic Selection\nIn choosing the topic ‘Multifaceted Analysis of Insurance Fraud,’ our intent is to delve deeply into the intricate and often interconnected factors that give rise to insurance fraud. This complexity is not just a mere academic interest; it is central to the real-world challenge of detecting and preventing fraudulent activities in the insurance sector. We are particularly drawn to the multifaceted nature of this issue – it is not driven by singular causes but is a tapestry woven from various threads including geographical influences, the specifics of insurance policies, the characteristics of those insured, the nature of the incidents, and the details of the vehicles involved.\nUnderstanding this interplay is not merely an exercise in data analysis; it’s about peeling back the layers to reveal how these diverse factors come together to create an environment where fraud can occur. Through our analysis, we aim to provide a comprehensive view of these elements, exploring how they individually and collectively contribute to the occurrence of fraudulent claims. This is crucial because effectively combating insurance fraud requires a holistic approach. By identifying patterns and correlations, we can better understand where vulnerabilities lie and, therefore, where interventions can be most effectively targeted.\nMoreover, our interest in this topic is fueled by the significant real-world implications of insurance fraud. It’s not just about financial losses to insurance companies; it’s about the broader impact on policyholders and the insurance industry as a whole. The ripple effects of fraud can be seen in increased premiums for honest customers and a potential loss of trust in the insurance system. By unraveling these complex relationships, our study seeks to contribute valuable insights that could aid in the development of more sophisticated and effective fraud detection and prevention strategies. Ultimately, the goal is to foster a more secure and trustworthy insurance landscape for all stakeholders."
  },
  {
    "objectID": "index.html#research-questions-and-areas-of-focus",
    "href": "index.html#research-questions-and-areas-of-focus",
    "title": "Insurance Claims",
    "section": "1.2 Research Questions and Areas of Focus",
    "text": "1.2 Research Questions and Areas of Focus\nIn embarking on this study, our aim is to dissect the multifaceted nature of insurance fraud through a series of focused research questions. These questions are designed not only to deepen our understanding of the phenomenon but also to uncover potential avenues for more effective fraud prevention strategies. The areas of focus that we have identified are pivotal in shaping the landscape of insurance fraud and include geographical trends, policy features, insured demographics, incident characteristics, and vehicle information.\nGeographical Trends: our first area of inquiry centers on the impact of geographical trends on insurance fraud. We are curious to explore whether certain regions or states exhibit higher incidences of fraudulent claims. Are there socio-economic or legislative factors in these regions that might contribute to this trend? Understanding geographical patterns can provide valuable insights into targeted fraud prevention measures.\nPolicy Features: Next, we aim to investigate the role of policy features in the likelihood of fraudulent claims. Do higher deductibles or specific types of coverage correlate with a higher incidence of fraud? This line of questioning seeks to understand how the structure and terms of insurance policies might inadvertently encourage or deter fraudulent activities.\nDemographic Characteristics: Another crucial aspect of our study is to examine whether specific demographic characteristics are more frequently associated with fraud. Does age, gender, education level, or occupation of the insured play a role in the propensity to commit insurance fraud? This exploration could highlight vulnerable segments or risk factors in policy underwriting.\nIncident Details: The nature of the incident itself is also a significant factor. We are interested in exploring how the details of the incident, such as its severity or type, correlate with the likelihood of a claim being fraudulent. For instance, are minor incidents more likely to be exaggerated, or do severe incidents have a higher likelihood of fraud?\nVehicle Information: Lastly, the type or model of the vehicle involved in the insurance claim might also influence the incidence of fraud. Are luxury vehicles more associated with fraudulent claims, or are there specific models or years that seem to be more prone to fraud?\nThrough these questions, we hope to uncover patterns and correlations that can aid in the development of more effective fraud detection tools and policies. This study is not just about identifying the ‘what’ of insurance fraud; it’s about understanding the ‘why’ and ‘how,’ which are crucial for any meaningful intervention in this area."
  },
  {
    "objectID": "index.html#background-context",
    "href": "index.html#background-context",
    "title": "Insurance Claims",
    "section": "1.3 Background Context",
    "text": "1.3 Background Context\nFor readers who may be new to the subject, it’s crucial to understand why a study on insurance fraud is not only relevant but essential. Insurance fraud, often perceived as a victimless crime, in fact, has far-reaching implications that extend beyond the insurance industry, affecting policyholders, insurance companies, and the broader economy.\nFirstly, for insurance companies, fraud represents a significant financial drain. The costs incurred due to fraudulent claims directly impact their bottom line. These costs are not just absorbed by the companies; they are typically passed on to policyholders in the form of higher premiums. Therefore, insurance fraud indirectly taxes honest customers, increasing their financial burden.\nBeyond the financial aspect, insurance fraud undermines the trust in the insurance system. When fraud becomes prevalent, it can lead to stricter claim scrutiny, potentially causing delays and added complications for genuine claimants. This erodes the foundational trust that policyholders place in their insurance providers – the assurance that in times of need, their claims will be handled fairly and efficiently.\nThe broader economic impact is also significant. High levels of insurance fraud can lead to increased costs for goods and services. For example, in the case of auto insurance fraud, increased premiums can elevate the operational costs for businesses relying on transportation, which may then be passed on to consumers.\nUnderstanding the various factors that influence insurance fraud is pivotal in developing effective mitigation strategies. By identifying and analyzing the trends, patterns, and correlations within this complex issue, stakeholders can tailor their approaches to combating fraud more effectively. This could include more sophisticated risk assessment models, targeted educational campaigns, and enhanced investigative practices.\nIn essence, this study aims to shed light on the intricate dynamics of insurance fraud, providing insights that could lead to more robust prevention and detection measures. Such efforts are vital in safeguarding the financial health of the insurance industry, protecting consumers from undue costs, and maintaining the integrity of the insurance process."
  },
  {
    "objectID": "index.html#objective",
    "href": "index.html#objective",
    "title": "Insurance Claims",
    "section": "1.4 Objective",
    "text": "1.4 Objective\nThe primary objective of this study is to dissect and analyze the intricate relationships between various factors that lead to insurance fraud. By delving into aspects such as geographical trends, policy features, demographic characteristics of the insured, the nature of the incidents, and vehicle-related information, the study aims to provide a comprehensive understanding of how these elements interplay and contribute to fraudulent activities in the insurance sector.\nThis analysis is not just an academic exercise; it is instrumental in shaping the future of insurance policies and fraud detection methods. Through a thorough examination of these multifaceted factors, the study seeks to identify key indicators and patterns of fraud, which can be leveraged to enhance the accuracy and efficiency of fraud detection. By pinpointing specific areas where fraud is more prevalent or identifying particular characteristics that are often associated with fraudulent claims, insurance companies can refine their risk assessment models and develop more targeted prevention strategies.\nFurthermore, the insights gained from this study have the potential to inform the development of more sophisticated policy structures and underwriting processes. This can lead to more balanced and fair pricing of insurance premiums, ensuring that honest policyholders are not unduly burdened by the costs associated with fraudulent activities.\nIn essence, the goal of this study is to contribute to the creation of a more secure, fair, and trustworthy insurance environment. By improving our understanding of the complexities surrounding insurance fraud, we can pave the way for more effective industry practices, ultimately benefiting insurance companies, policyholders, and the broader economy alike."
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "2.1 Description",
    "text": "2.1 Description\nThe data is in .csv format. There are 1,000 rows with 40 columns, however, the column “_c39” is all null so we will drop it before our analysis.\nThere are 38 attributes (features) in total in the data. They can be divided into five main categories, which are Personal and Policy Information, Location and Vehicle Information, Incident Details, Claim Information and Other Attributes:\n\nPersonal and Policy Information: It contains columns for customer characteristics such as months_as_customer, age, policy_number, policy_bind_date, policy_state, policy_csl (Combined Single Limit), policy_deductable, policy_annual_premium, and umbrella_limit.\nLocation and Vehicle Information: There are details about the insured_zip, incident_location, incident_hour_of_the_day, as well as information about the vehicle involved like auto_make, auto_model, and auto_year.\nIncident Details: The dataset includes specific details about incidents such as incident_date, incident_type, collision_type, incident_severity, authorities_contacted, and whether a police_report_available.\nClaim Information: This encompasses the total_claim_amount, injury_claim, property_claim, vehicle_claim, and whether the claim was reported as fraud (fraud_reported).\nOther Attributes: Additional attributes include details about the insured like insured_sex, insured_education_level, insured_occupation, insured_hobbies, insured_relationship, as well as information about witnesses, bodily injuries, and other aspects related to the insurance claims.\n\nBelow is what our data looks like:\n\n\nCode\ndata &lt;- read.csv('insurance_claims.csv', na.strings = c(\"?\", \"NA\"))\nhead(data)\n\n\n  months_as_customer age policy_number policy_bind_date policy_state policy_csl\n1                328  48        521585       2014-10-17           OH    250/500\n2                228  42        342868       2006-06-27           IN    250/500\n3                134  29        687698       2000-09-06           OH    100/300\n4                256  41        227811       1990-05-25           IL    250/500\n5                228  44        367455       2014-06-06           IL   500/1000\n6                256  39        104594       2006-10-12           OH    250/500\n  policy_deductable policy_annual_premium umbrella_limit insured_zip\n1              1000               1406.91              0      466132\n2              2000               1197.22        5000000      468176\n3              2000               1413.14        5000000      430632\n4              2000               1415.74        6000000      608117\n5              1000               1583.91        6000000      610706\n6              1000               1351.10              0      478456\n  insured_sex insured_education_level insured_occupation insured_hobbies\n1        MALE                      MD       craft-repair        sleeping\n2        MALE                      MD  machine-op-inspct         reading\n3      FEMALE                     PhD              sales     board-games\n4      FEMALE                     PhD       armed-forces     board-games\n5        MALE               Associate              sales     board-games\n6      FEMALE                     PhD       tech-support  bungie-jumping\n  insured_relationship capital.gains capital.loss incident_date\n1              husband         53300            0    2015-01-25\n2       other-relative             0            0    2015-01-21\n3            own-child         35100            0    2015-02-22\n4            unmarried         48900       -62400    2015-01-10\n5            unmarried         66000       -46000    2015-02-17\n6            unmarried             0            0    2015-01-02\n             incident_type  collision_type incident_severity\n1 Single Vehicle Collision  Side Collision      Major Damage\n2            Vehicle Theft            &lt;NA&gt;      Minor Damage\n3  Multi-vehicle Collision  Rear Collision      Minor Damage\n4 Single Vehicle Collision Front Collision      Major Damage\n5            Vehicle Theft            &lt;NA&gt;      Minor Damage\n6  Multi-vehicle Collision  Rear Collision      Major Damage\n  authorities_contacted incident_state incident_city  incident_location\n1                Police             SC      Columbus     9935 4th Drive\n2                Police             VA     Riverwood       6608 MLK Hwy\n3                Police             NY      Columbus  7121 Francis Lane\n4                Police             OH     Arlington   6956 Maple Drive\n5                  None             NY     Arlington       3041 3rd Ave\n6                  Fire             SC     Arlington 8973 Washington St\n  incident_hour_of_the_day number_of_vehicles_involved property_damage\n1                        5                           1             YES\n2                        8                           1            &lt;NA&gt;\n3                        7                           3              NO\n4                        5                           1            &lt;NA&gt;\n5                       20                           1              NO\n6                       19                           3              NO\n  bodily_injuries witnesses police_report_available total_claim_amount\n1               1         2                     YES              71610\n2               0         0                    &lt;NA&gt;               5070\n3               2         3                      NO              34650\n4               1         2                      NO              63400\n5               0         1                      NO               6500\n6               0         2                      NO              64100\n  injury_claim property_claim vehicle_claim auto_make auto_model auto_year\n1         6510          13020         52080      Saab        92x      2004\n2          780            780          3510  Mercedes       E400      2007\n3         7700           3850         23100     Dodge        RAM      2007\n4         6340           6340         50720 Chevrolet      Tahoe      2014\n5         1300            650          4550    Accura        RSX      2009\n6         6410           6410         51280      Saab         95      2003\n  fraud_reported X_c39\n1              Y    NA\n2              Y    NA\n3              N    NA\n4              Y    NA\n5              N    NA\n6              Y    NA"
  },
  {
    "objectID": "data.html#research-plan",
    "href": "data.html#research-plan",
    "title": "2  Data",
    "section": "2.2 Research plan",
    "text": "2.2 Research plan\nOur project will initially focus on an exploratory analysis of each category of data in the dataset, aiming to unearth potential connections among them and their relationship with insurance fraud. Then we will employ techniques such as regression analysis and Principal Component Analysis (PCA). These methods will enable us to compare and quantify the impact of different factors on the likelihood of fraud.\nBy conducting this multi-dimensional analysis, we will leverage the dataset’s comprehensive range of data - encompassing geographical trends, policy features, demographic characteristics, incident specifics, and vehicle information. This approach will not only help us identify patterns and insights in each data category but also allow us to understand the cumulative impact of these factors on insurance fraud."
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.3 Missing value analysis",
    "text": "2.3 Missing value analysis\nIn this dataset, all the missing data are represented by “?” elements, so we need to replace all “?” elements with null values. Besides, there is one column named “_c39” with all null values that can be dropped.\n\n\nCode\ndata &lt;- read.csv('insurance_claims.csv', na.strings = c(\"?\", \"NA\"))\ndata &lt;- subset(data, select = -X_c39)\n\n\nThen calculate the number of missing values in each column and visualize the missing data using a bar plot for an overview.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\n# Count missing values\nmissing_values &lt;- sapply(data, function(x) sum(is.na(x)))\nmissing_data_frame &lt;- data.frame(column = names(missing_values), missing_count = missing_values)\n\n# Create a data frame for plotting\nmissing_data_frame &lt;- data.frame(column = names(missing_values), missing_count = missing_values)\n\n# Create the bar plot with ggplot2\nggplot(missing_data_frame |&gt; arrange(desc(missing_count)), aes(x = reorder(column, missing_count), y = missing_count)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +  # Reverse the coordinate system\n  xlab(\"Column\") +\n  ylab(\"Number of Missing Values\") +\n  ggtitle(\"Missing Values per Column\") # Add titles and labels as needed\n\n\n\n\n\nObviously, there are only three columns with missing values, so we proceed to drop all the other columns and use plot_missing in redav to plot the them.\n\n\nCode\nlibrary(redav)\nplot_missing(subset(data, select = c(\"police_report_available\",\"property_damage\",\"collision_type\")), percent = FALSE)\n\n\n\n\n\nThe patterns indicated by these plots suggest that the missing data is mostly concentrated in a single variable which is illstrated by the fact that case 2 and 3 in missing pattern are significantly more than other cases. Missingness spreading across several variables needs to be handled carefully, as it could bias the results of any analysis performed on the dataset. Techniques such as imputation or the use of models that can handle missing data might be necessary to account for the missing values."
  },
  {
    "objectID": "results.html#section",
    "href": "results.html#section",
    "title": "3  Results",
    "section": "3.1 1",
    "text": "3.1 1"
  },
  {
    "objectID": "results.html#geographical-trends",
    "href": "results.html#geographical-trends",
    "title": "3  Results",
    "section": "3.1 Geographical Trends",
    "text": "3.1 Geographical Trends\nHere, we primarily focus on two variables: ‘policy_state,’ which means the state where the insurance policy was issued; and ‘incident_state,’ which means the state where the incident occurred.\n\n\nCode\ndata$fraud_reported_numeric &lt;- ifelse(data$fraud_reported == \"Y\", 1, 0)\n\nfraud_rate_by_state &lt;- aggregate(fraud_reported_numeric ~ incident_state, data, mean)\n\nfraud_rate_by_state$fraud_rate &lt;- fraud_rate_by_state$fraud_reported_numeric * 100\n\nfraud_rate_by_state$fraud_reported_numeric &lt;- NULL\n\nstate_abbreviations &lt;- c(\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n                         \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n                         \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n                         \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n                         \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\")\nstate_names &lt;- c(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\",\n                 \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\",\n                 \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\",\n                 \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\",\n                 \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\",\n                 \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\",\n                 \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\",\n                 \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\",\n                 \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\")\n\nstate_map &lt;- setNames(state_names, state_abbreviations)\n\nfraud_rate_by_state$incident_state &lt;- tolower(state_map[fraud_rate_by_state$incident_state])\n\nnames(fraud_rate_by_state) &lt;- c(\"region\", \"value\")\n\n\n\n\nCode\nlibrary(choroplethr)\nlibrary(ggplot2)\nlibrary(RColorBrewer)\n\nmap &lt;- state_choropleth(fraud_rate_by_state, \n                        title = \"Fraud Rate by State\", \n                        legend = \"Fraud Rate\") +\n       scale_fill_brewer(palette = \"Reds\", name = \"Fraud Rate\")\n\nmap + coord_fixed(xlim = c(-85, -70), ylim = c(30, 45))\n\n\n\n\n\nThis map provides a visual representation of insurance fraud rates across a selection of states, specifically focusing on a certain region in the United States. The data is clearly delimited to just seven states, each shaded according to the severity of the fraud rate as per the accompanying legend.\nIn the middle portion of the map, we can see that Ohio (OH) stands out with the darkest shade of red, which, according to the legend, signifies the highest fraud rate among the states presented. This darker hue draws immediate attention and could indicate a significant concern regarding insurance fraud within the state.\nSurrounding Ohio, the states of Pennsylvania (PA), West Virginia (WV), and Maryland (MD) are shaded with a moderately lighter color. This suggests that while their fraud rates are still notable, they are less severe when compared to Ohio’s rate. Each state’s shade provides a quick visual clue to its relative position on the fraud rate scale, with the map serving as a quick reference to compare the extent of fraud rates across these neighboring states.\nFurther south, Virginia (VA), North Carolina (NC), and South Carolina (SC) are depicted with varying intensities of red. North Carolina and South Carolina, in particular, are colored with a darker tone, which implies that their fraud rates are relatively high, although still not as high as Ohio’s. Virginia, on the other hand, shows a lighter shade, indicating a lower fraud rate compared to its southern neighbors.\nEach state’s coloration on the map is a direct indicator of the rate of insurance fraud, with darker shades correlating to higher rates. This visual distinction serves as a crucial tool for identifying patterns and areas that may require more in-depth analysis or targeted anti-fraud measures.\n\n\nCode\ndata$fraud_reported_numeric &lt;- ifelse(data$fraud_reported == \"Y\", 1, 0)\n\nfraud_rate_by_state &lt;- aggregate(fraud_reported_numeric ~ policy_state, data, mean)\n\nfraud_rate_by_state$fraud_rate &lt;- fraud_rate_by_state$fraud_reported_numeric * 100\n\nfraud_rate_by_state$fraud_reported_numeric &lt;- NULL\n\nfraud_rate_by_state$policy_state &lt;- tolower(state_map[fraud_rate_by_state$policy_state])\n\nnames(fraud_rate_by_state) &lt;- c(\"region\", \"value\")\n\nmap &lt;- state_choropleth(fraud_rate_by_state, \n                        title = \"Fraud Rate by State\", \n                        legend = \"Fraud Rate\") +\n       scale_fill_brewer(palette = \"Reds\", name = \"Fraud Rate\")\n\nmap + coord_fixed(xlim = c(-95, -80), ylim = c(36, 45))\n\n\n\n\n\nHere, only three states are highlighted, indicating the presence of data for these states.\nThe state of Ohio (OH) is colored with the darkest shade of red on the map, indicating the highest rate of insurance fraud in relation to where the insurance contracts were issued. The legend to the right suggests that Ohio’s fraud rate is between 25.9 and the unspecified upper limit of the scale.\nIndiana (IN) is shaded with a medium intensity, suggesting a moderate rate of insurance fraud as per the legend, which places the state’s rate between 25.5 and 22.8.\nIllinois (IL) appears with the lightest shade of red, signifying the lowest fraud rate among the three states, with its rate falling at or just above 22.8, the lowest value provided on the legend.\nThis map differs from the first in the number of states included as well as the range of fraud rates represented. The narrower range of rates suggests a more focused analysis or a more uniform distribution of fraud rates across these states. The clear visual contrast between Ohio and the other two states underscores Ohio’s prominence in insurance fraud rates for contracts originating within the state. This could prompt further investigation into the factors contributing to Ohio’s higher rate of fraud and encourage targeted efforts to address the issue.\n\n\nCode\nlibrary(ggalluvial)\nlibrary(alluvial)\n\nselected_data &lt;- data %&gt;% \n  select(policy_state, incident_state, fraud_reported)\n\nfrequency_data &lt;- selected_data %&gt;% \n  count(policy_state, incident_state, fraud_reported)\n\nggplot(data = frequency_data, \n       aes(axis1 = policy_state, axis2 = incident_state, axis3 = fraud_reported, y = n)) +\n  geom_alluvium(aes(fill = fraud_reported)) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  scale_x_discrete(limits = c(\"Policy State\", \"Incident State\", \"Fraud Reported\")) +\n  theme_minimal() +\n  theme(\n    axis.title.y = element_blank(), \n    axis.text.y = element_blank(), \n    axis.ticks.y = element_blank(), \n    panel.border = element_blank(), \n    panel.grid.major = element_blank(), \n    panel.grid.minor = element_blank() \n  ) +\n  labs(title = \"Relationships among Policy State, Incident State, and Fraud Reported\",\n       x = \"\") \n\n\n\n\n\nThe alluvial diagram visually captures the complexity of relationships between the state where an insurance policy is signed, the state where the incident occurs, and the incidence of reported fraud. Starting from the left, we see policy origins in Illinois, Indiana, and Ohio, with lines flowing to the middle column representing the states where incidents have occurred. The thickness of these lines indicates the volume of policies linking to incidents in each state, with Ohio showing a particularly thick band leading back to itself, suggesting a high number of in-state incidents for policies underwritten there.\nThe flow towards the rightmost column, which marks whether fraud was reported, reveals significant variances. Some Incident States have a higher propensity for fraud reports, as indicated by the thicker blue bands moving towards the ‘Y’ for yes. Ohio again stands out, with a heavy flow to the ‘Y’, hinting at a higher frequency or likelihood of fraud reports for incidents connected to Ohio policies. This could point to specific vulnerabilities or enforcement challenges within the state.\nMoreover, the distribution of flows from Incident States to the ‘N’ and ‘Y’ outcomes is not even, implying that while some states predominantly have non-fraudulent claims, others have a mix or a tendency towards fraud. For instance, Pennsylvania has a substantial band flowing to the ‘Y’, which could signal an area of concern for insurers and regulators alike.\nThe diagram’s bands, in their varying widths and directions, create a narrative of how insurance incidents and fraud reports are interconnected across state lines. The intertwining paths also suggest the potential for complex fraud schemes that span multiple jurisdictions, potentially complicating the detection and investigation processes. The data represented here, if further dissected, could be a rich resource for developing targeted interventions to mitigate fraud risks. It could also guide insurers on where to focus their efforts in terms of fraud education, prevention, and detection strategies, particularly in those states with thicker bands leading to the ‘Y’ outcome.\nBut the quantitative characteristics are not really obvious."
  },
  {
    "objectID": "results.html#incident-details",
    "href": "results.html#incident-details",
    "title": "3  Results",
    "section": "3.2 Incident Details",
    "text": "3.2 Incident Details\n\n3.2.1 capital situation\nwe mainly focus on two variables: ‘capital-gains,’ which means the capital gains of the insured individual; and ‘capital-loss,’ which means the capital losses of the insured individual.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\ndata &lt;- data %&gt;%\n  mutate(id = row_number())\n\nlong_data &lt;- data %&gt;%\n  select(id, capital.loss, capital.gains) %&gt;%\n  pivot_longer(cols = -id, names_to = \"variable\", values_to = \"value\")\n\nggplot(long_data, aes(x = variable, y = value, group = id)) +\n  geom_line(alpha = 0.06) +\n  theme_minimal() +\n  labs(title = \"Slope Graph for Capital Loss and Capital Gain\",\n       x = \"\",\n       y = \"Value\")\n\n\n\n\n\nSlope graphs are excellent for showing changes between two points in time or, as in this case, between two different conditions for a number of subjects.\nIn the graph, each line represents an entity. The left side labeled ‘capital.gains’ shows the starting value of capital gains, and the right side labeled ‘capital.loss’ shows the resulting value of capital losses. The crossing point at ‘Value’ zero could be interpreted as the break-even point where gains equal losses.\nThe most striking aspect of this graph is the density of lines near the zero point on both sides, which indicates that for the majority of entities, both capital gains and losses are close to zero. This suggests a concentration of entities with minimal capital gains or losses. However, the spread of lines fanning out towards the extremes of the graph, especially on the capital loss side, indicates that there are also entities with significant losses, some reaching as high as 100,000 units in the negative. The capital gains side shows fewer entities with extreme positive values, but there are still a notable number of lines reaching toward the upper positive range.\nThe steepness of the slope indicates the magnitude of change from gain to loss. Steeper slopes suggest more significant changes. For instance, lines that fall steeply to the right indicate entities that have moved from a position of capital gain to a substantial capital loss. Conversely, lines that rise steeply towards the right suggest entities that have transitioned from a smaller capital gain to a more substantial gain or from a loss to a gain.\nThis slope graph does not just tell us about individual entities but also speaks to the overall distribution of gains and losses within the dataset. The visual impact of the dense cluster of lines near the center versus the sparse but dramatic lines toward the extremes may prompt further questions about the factors contributing to such a wide disparity in capital gains and losses. Such a graph could be of particular interest to financial analysts, economists, or business strategists looking to understand the volatility of gains and losses within a market or a portfolio of investments.\n\n\n3.2.2 Time\nHere, we mainly focus on two variables: ‘incident_date,’ which means the date of the incident; and ‘incident_hour_of_the_day,’ which means the hour of the day when the incident occurred.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(lubridate)\n\ndata$incident_date &lt;- as.Date(data$incident_date, format = \"%m/%d/%Y\")\n\ndata$fraud_flag &lt;- ifelse(data$fraud_reported == 'Y', 1, 0)\n\nfraud_rate_by_date &lt;- data %&gt;%\n  group_by(incident_date) %&gt;%\n  summarise(fraud_rate = mean(fraud_flag))\n\nggplot(fraud_rate_by_date, aes(x = incident_date, y = fraud_rate * 100)) +\n  geom_smooth(method = \"loess\", se = FALSE, span = 0.3) + \n  theme_minimal() +\n  labs(title = \"Fraud Rate by Incident Date\",\n       x = \"Incident Date\",\n       y = \"Fraud Rate(%)\")\n\n\n\n\n\nThe y-axis indicates the fraud rate as a percentage, and the x-axis represents the date of the incident. This type of graph is commonly used to observe trends, patterns, or fluctuations in data over a specified time period.\nIn the graph, there are several peaks and troughs, indicating variability in the fraud rate over the given time. The first notable peak occurs shortly after January 1st, where the fraud rate approaches 30%. This is followed by a sharp decline, then another peak around mid-January. Following this, the fraud rate generally trends downward with some fluctuations, until a significant drop is observed towards the end of February, where the fraud rate dips below 20%. The rate then sharply increases again as the timeline approaches March.\nThese fluctuations could be indicative of various external factors influencing the fraud rate. For instance, increased fraud rates at the beginning of the year could be related to the closure of financial reporting periods, leading to a rush to meet or manipulate targets. The significant dip at the end of February could be due to the end of a financial quarter, increased vigilance from anti-fraud departments, or even seasonal trends that affect fraudulent activities.\nAnalyzing such a graph could provide insights for businesses and regulatory bodies into when fraud is most likely to occur, which could then inform the timing of fraud prevention and detection efforts. It’s important to consider that such a graph represents a simplified view of complex behaviors and would likely need to be supplemented with additional data and analysis to understand the underlying causes of these trends.\n\n\nCode\nfraud_rate_by_hour &lt;- data %&gt;%\n  group_by(incident_hour_of_the_day) %&gt;%\n  summarise(fraud_rate = mean(fraud_flag) * 100)  \n\nggplot(fraud_rate_by_hour, aes(x = incident_hour_of_the_day, y = fraud_rate)) +\n  geom_smooth(method = \"loess\", se = FALSE, span = 0.3) +  \n  theme_minimal() +\n  labs(title = \"Fraud Rate by Incident Hour of the Day\",\n       x = \"Incident Hour of the Day\",\n       y = \"Fraud Rate(%)\")\n\n\n\n\n\nThe x-axis represents the 24-hour clock, while the y-axis shows the fraud rate. The graph’s shape, with its peaks and valleys, suggests that the incidence of fraud fluctuates considerably throughout the day.\nObserving the pattern, there are notable peaks around the 3rd hour, 9th hour, 15th hour, and towards the 23rd hour. These times might correspond with certain daily activities or behaviors that present more opportunities for fraudulent activities to occur or be reported. For example, the peak in the early hours of the morning could correspond to a time when fewer controls are in place, while the midday and mid-afternoon peaks could align with high transaction volumes.\nConversely, the graph shows troughs or lower rates of fraud at around the 6th hour, 12th hour, and 18th hour. These could be times when vigilance is higher or when there are fewer transactions taking place, leading to a lower rate of fraudulent activity being recorded.\nIt’s challenging to discern a clear trend across the hours, as the graph does not follow a simple or predictable pattern. Instead, it suggests that the fraud rate is subject to multiple influences and varies significantly as the day progresses. This variability would be expected as different types of fraudulent activities might have different ‘prime times’ depending on various factors such as human behavior, business hours, and monitoring systems in place.\nFor a more comprehensive analysis, additional context would be needed regarding the types of fraud represented, the mechanisms of fraud detection, and the specifics of the reporting process. Moreover, this data could be correlated with other variables such as transaction volumes, to understand whether peaks in fraud rates correspond with higher activity levels. This graph provides a starting point for identifying when during the day fraud prevention measures might be most necessary or when to be most alert for fraudulent activity.\n\n\n3.2.3 Type\nFocus on three variables: ‘incident_type,’ which is the type of the incident; ‘collision_type,’ which is the type of collision, if applicable; and ‘incident_severity,’ which is the severity of the incident.\n\n\nCode\ndata1 &lt;- subset(data, !is.na(incident_type) & !is.na(collision_type) & !is.na(incident_severity) & !is.na(fraud_reported))\n\nvcd::mosaic(fraud_reported ~ incident_type + collision_type + incident_severity, data1, direction = c('h', 'h', 'v'), main = \"Association between Age.Groups and Subchapter\")\n\n\n\n\n\nThe mosaic plot visualizes the characteristics of vehicular accidents in relation to insurance fraud. The ‘Y’ and ‘N’ labels distinguish between incidents that are fraudulent and non-fraudulent, respectively. The horizontal categories represent the severity of the incident—Major Damage, Minor Damage, and Total Loss—while the vertical categories indicate the type of collision—Single Vehicle, Side, Rear, and Front Collisions.\nFrom the plot, we can observe patterns:\nMajor Damage has a high frequency of fraudulent claims (‘Y’) compared to non-fraudulent (‘N’). This might suggest that fraudulent claims are more likely to be filed for incidents reported with major damage.\nSingle Vehicle Collisions show a significant presence of fraud, as indicated by the darker shading in the ‘Y’ category. This could imply that such collisions are either prone to fraudulent claims or are more often associated with fraudulent activities.\nThere’s a notable difference in the frequency of fraud between different collision types. Side and Rear Collisions have a relatively balanced distribution of fraudulent and non-fraudulent claims, whereas Front Collisions seem to have a lower incidence of fraud.\nThe category for Total Loss has less shading overall, which could indicate fewer claims in this category, but the proportion of fraudulent claims within it is comparable to that of Major and Minor Damage. The rectangles’ size indicates the count or proportion of incidents, with larger rectangles showing more frequent occurrences. The darker the rectangle, the higher the incidence of fraud in that particular category. For instance, a large, dark rectangle in the ‘Major Damage’ and ‘Single Vehicle Collision’ categories suggests a high number of fraudulent claims are reported for single-vehicle incidents with major damage.\nUnderstanding these patterns can be crucial for insurance companies in detecting potential fraud. For example, if Single Vehicle Collisions with Major Damage frequently result in fraudulent claims, insurers might focus their investigative resources on such incidents. Similarly, the lower shading for Total Loss incidents might prompt a review of the criteria or processes by which these claims are adjudicated.\nThe visualization effectively highlights the intersection of various factors with the occurrence of fraud, providing a clear representation of where fraudulent activities are most prevalent. It serves as a strategic tool for identifying patterns and potential vulnerabilities within the sphere of vehicle insurance claims.\n\n\nCode\nselected_data &lt;- data1 %&gt;% \n  select(incident_type, collision_type, incident_severity, fraud_reported)\n\nfrequency_data &lt;- selected_data %&gt;% \n  count(incident_type, collision_type, incident_severity, fraud_reported)\n\nggplot(data = frequency_data, \n       aes(axis1 = incident_type, axis2 = collision_type, axis3 = incident_severity, axis4 = fraud_reported, y = n)) +\n  geom_alluvium(aes(fill = fraud_reported)) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  scale_x_discrete(limits = c(\"incident_type\", \"collision_type\", \"incident_severity\", \"fraud_reported\")) + \n  theme_minimal() +\n  theme(\n    axis.title.y = element_blank(), \n    axis.text.y = element_blank(), \n    axis.ticks.y = element_blank(), \n    panel.border = element_blank(), \n    panel.grid.major = element_blank(), \n    panel.grid.minor = element_blank() \n  ) +\n  labs(title = \"Relationships among Policy State, Incident State, and Fraud Reported\",\n       x = \"\") \n\n\n\n\n\nIn this alluvial diagram, the relationships among the type of incident, the collision type, the severity of the incident, and whether fraud was reported are depicted.\nThe diagram begins with ‘incident_type’ on the left, branching into different types of collisions such as ‘Multi-vehicle Collision’, ‘Single Vehicle Collision’, etc. These categories then flow into ‘collision_type’, which further divides into ‘Front Collision’, ‘Rear Collision’, ‘Side Collision’, and so on. Following this, the lines feed into ‘incident_severity’, which categorizes the incidents into ‘Major Damage’, ‘Minor Damage’, and ‘Total Loss’. The final set of connections flows into ‘fraud_reported’, distinguishing between incidents where fraud was reported (‘Y’) and those where it was not (‘N’).\nIn the visualization:\nThe thickness of the bands corresponds to the volume of incidents, with wider bands indicating a larger number of cases.\nThe color of the bands differentiates between incidents where fraud was reported (blue) and not reported (pink).\nThe intertwining of the bands illustrates the complex relationship between the variables. For instance, we can see that Single Vehicle Collisions have a significant flow into both ‘Major Damage’ and ‘Minor Damage’, but a notably smaller band flows into ‘Total Loss’.\nThere is a visible flow of blue bands (indicating fraud) across various types of collisions and severities, suggesting that fraudulent claims are not confined to any single category of incident type or severity.\nThis diagram allows us to observe not just the volume of incidents and fraud within each category, but also the proportions between them. For example, a thick blue band leading from ‘Rear Collision’ to ‘Minor Damage’ and then to ‘Y’ suggests a higher incidence of fraud reported in minor damages resulting from rear collisions.\n\n\n3.2.4 damage and trustworthiness\nThis time we focus on four variables to explore their relationship with fraud: ‘property_damage’, which indicates if there was any property damage; ‘bodily_injuries’, the number of bodily injuries in the incident; ‘police_report_available’, which indicates if a police report is available; and ‘witnesses’, the number of witnesses to the incident.\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\ndata1 &lt;- subset(data, !is.na(property_damage) & !is.na(bodily_injuries))\n\ndata1$fraud_reported_flag &lt;- ifelse(data1$fraud_reported == \"Y\", 1, 0)\n\nfraud_rates &lt;- data1 %&gt;%\n  group_by(property_damage, bodily_injuries) %&gt;%\n  summarise(fraud_rate = mean(fraud_reported_flag, na.rm = TRUE)) %&gt;%\n  ungroup()\n\np1 &lt;- ggplot(fraud_rates, aes(x = property_damage, y = bodily_injuries, fill = fraud_rate)) +\n  geom_tile() + \n  scale_fill_gradient(low = \"white\", high = \"red\", labels = scales::percent_format()) +\n  theme_minimal() +\n  labs(x = \"Bodily Injuries\", y = \"Property Damage\", fill = \"Fraud Rate\") +\n  geom_text(aes(label = scales::percent(fraud_rate)), size = 4, colour = \"black\")\n\n\n\n\nCode\nlibrary(patchwork)\n\ndata2 &lt;- subset(data, !is.na(police_report_available) & !is.na(witnesses))\n\ndata2$fraud_reported_flag &lt;- ifelse(data2$fraud_reported == \"Y\", 1, 0)\n\nfraud_rates &lt;- data2 %&gt;%\n  group_by(police_report_available, witnesses) %&gt;%\n  summarise(fraud_rate = mean(fraud_reported_flag, na.rm = TRUE)) %&gt;%\n  ungroup()\n\np2 &lt;- ggplot(fraud_rates, aes(x = police_report_available, y = witnesses, fill = fraud_rate)) +\n  geom_tile() + \n  scale_fill_gradient(low = \"white\", high = \"red\", labels = scales::percent_format()) +\n  theme_minimal() +\n  labs(x = \"police_report_available\", y = \"witnesses\", fill = \"Fraud Rate\") +\n  geom_text(aes(label = scales::percent(fraud_rate)), size = 4, colour = \"black\")\n\n(p1 | p2)\n\n\n\n\n\nThere are two heatmaps that show the fraud rate in relation to various factors associated with vehicle incidents.\nThe left chart correlates the property damage level and bodily injuries to the fraud rate. The levels of property damage are ranked from 0 to 2, and the presence of bodily injuries is indicated by ‘YES’ or ‘NO’. Each bar is color-coded to represent the fraud rate, with darker shades indicating higher rates. It’s evident that incidents with higher levels of property damage and bodily injuries have a higher fraud rate, with the highest fraud rate occurring at property damage level 2 with bodily injuries present.\nThe right chart correlates the number of witnesses and the availability of a police report to the fraud rate. The number of witnesses is ranked from 0 to 3, and the availability of a police report is denoted as ‘YES’ or ‘NO’. Here, we see that a higher number of witnesses correlates to a higher fraud rate, which is counterintuitive as one might expect more witnesses to deter fraudulent claims. The availability of a police report seems to have a mixed impact on the fraud rate, with the absence of a police report correlating to a higher fraud rate in cases with one witness, but a lower fraud rate in cases with two witnesses.\nThese charts suggest complex relationships between these variables and the incidence of fraud. The data might imply that certain scenarios, such as more severe accidents with bodily injuries, could be more susceptible to fraudulent claims. Additionally, the presence of a police report doesn’t consistently decrease the fraud rate, which could suggest that the mere availability of official documentation is not a strong deterrent to fraud.\n\n\n3.2.5 Claim\nThis time, we are primarily focusing on four numerical variables: total claim amount (total_claim_amount), claim amount for injuries (injury_claim), claim amount for property damage (property_claim), and claim amount for vehicle damage (vehicle_claim).\n\n\nCode\nlibrary(ggplot2)\n\np1 &lt;- ggplot(data, aes(x = total_claim_amount, y = fraud_reported)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(x = \"Total Claim Amount\", y = \"Fraud Reported\", title = \"Total Claim Amount by Fraud Reported\")\n\np2 &lt;- ggplot(data, aes(x = injury_claim, y = fraud_reported)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(x = \"claim amount for injuries\", y = \"Fraud Reported\", title = \"Total Claim Amount by Fraud Reported\")\n\np3 &lt;- ggplot(data, aes(x = property_claim, y = fraud_reported)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(x = \"claim amount for property damage\", y = \"Fraud Reported\", title = \"Total Claim Amount by Fraud Reported\")\n\np4 &lt;- ggplot(data, aes(x = vehicle_claim, y = fraud_reported)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(x = \"claim amount for vehicle damage\", y = \"Fraud Reported\", title = \"Total Claim Amount by Fraud Reported\")\n\n(p1 | p2) /\n(p3 | p4)\n\n\n\n\n\nThe image contains four box-and-whisker plots, each comparing the distribution of total claim amounts for different categories based on whether fraud was reported (‘Y’ for yes, ‘N’ for no).\nThe first plot shows the total claim amount across all categories. The ‘Y’ fraud reported claims have a higher median and more variability compared to the ‘N’ non-fraudulent claims. This suggests that fraudulent claims tend to be for higher amounts and have a wider range of claim values.\nThe second plot focuses on claim amounts for injuries. Here, the difference between the median claim amounts for fraudulent and non-fraudulent claims is less pronounced than in the total claim amount. Still, fraudulent injury claims show a greater range and higher outliers, indicating that fraudulent injury claims can reach higher amounts than typical non-fraudulent claims.\nThe third plot presents claim amounts for property damage. The fraudulent claims (‘Y’) again show a higher median than non-fraudulent claims (‘N’), with a few high-value outliers suggesting that while most fraudulent property damage claims are similar in amount to non-fraudulent claims, some can be significantly higher.\nThe fourth plot examines claim amounts for vehicle damage specifically. The fraudulent claims show a higher median and greater variability, similar to the first plot, indicating that fraudulent claims for vehicle damage also tend to be higher and more varied than non-fraudulent ones.\nIn each plot, the presence of outliers in the ‘Y’ fraud reported groups indicates that while most fraudulent claims are within a certain range, there are exceptional cases with very high claim amounts. These outliers could be indicative of more significant cases of fraud.\nOverall, these visualizations suggest that fraudulent claims are generally associated with higher claim amounts across various types of damages and that there is a greater range of claim amounts within fraudulent claims compared to non-fraudulent ones. This data can be particularly useful for insurance companies when designing their fraud detection algorithms and risk assessment models."
  },
  {
    "objectID": "results.html#combined-relationship",
    "href": "results.html#combined-relationship",
    "title": "3  Results",
    "section": "3.3 combined relationship",
    "text": "3.3 combined relationship\n\n3.3.1 Time\n\n\nCode\nlibrary(lubridate)\n\n# data preprocess \ndata &lt;- read.csv('insurance_claims.csv', na.strings = c(\"?\", \"NA\"))\ndata &lt;- subset(data, select = -X_c39)\n\ndata$incident_date &lt;- mdy(data$incident_date) # mdy() is a lubridate function for mm/dd/yyyy format\ndata$policy_bind_date &lt;- mdy(data$policy_bind_date)\n\ndata$policy_hold_duration_months &lt;- interval(start = data$policy_bind_date, end = data$incident_date) %/% months(1)\n\n\n\n\nCode\nlibrary(reshape2)\n\nfraud_y_data &lt;- subset(data, fraud_reported == \"Y\")\nfraud_n_data &lt;- subset(data, fraud_reported == \"N\")\n\nfraud_y_data$duration_group &lt;- cut(fraud_y_data$policy_hold_duration_months, breaks=seq(0, 300, by=20), include.lowest=TRUE, right=FALSE)\nfraud_y_data$customer_group &lt;- cut(fraud_y_data$months_as_customer, breaks=seq(0, 480, by=20), include.lowest=TRUE, right=FALSE)\n\nfraud_n_data$duration_group &lt;- cut(fraud_n_data$policy_hold_duration_months, breaks=seq(0, 320, by=20), include.lowest=TRUE, right=FALSE)\nfraud_n_data$customer_group &lt;- cut(fraud_n_data$months_as_customer, breaks=seq(0, 480, by=20), include.lowest=TRUE, right=FALSE)\n\nheatmap_data_y &lt;- fraud_y_data %&gt;%\n  group_by(duration_group, customer_group) %&gt;%\n  summarise(n = n(), .groups = 'drop') %&gt;%\n  spread(key = customer_group, value = n, fill = 0)\n\nheatmap_data_n &lt;- fraud_n_data %&gt;%\n  group_by(duration_group, customer_group) %&gt;%\n  summarise(n = n(), .groups = 'drop') %&gt;%\n  spread(key = customer_group, value = n, fill = 0)\n\nheatmap_data_y_long &lt;- gather(heatmap_data_y, key = \"customer_group\", value = \"n\", -duration_group)\nheatmap_data_n_long &lt;- gather(heatmap_data_n, key = \"customer_group\", value = \"n\", -duration_group)\n\nheatmap_data_y_long$customer_group &lt;- factor(heatmap_data_y_long$customer_group, levels = unique(heatmap_data_y_long$customer_group))\nheatmap_data_n_long$customer_group &lt;- factor(heatmap_data_n_long$customer_group, levels = unique(heatmap_data_n_long$customer_group))\n\nheatmap_data_y_long$duration_group &lt;- factor(heatmap_data_y_long$duration_group, levels = unique(heatmap_data_y_long$duration_group))\nheatmap_data_n_long$duration_group &lt;- factor(heatmap_data_n_long$duration_group, levels = unique(heatmap_data_n_long$duration_group))\n\np1 &lt;- ggplot(heatmap_data_y_long, aes(x = duration_group, y = customer_group, fill = n)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"red\") +\n  labs(title = \"Fraud Reported = Y\", x = \"Policy Hold Duration Group\", y = \"Months as Customer Group\") +\n  theme_minimal()\n\np2 &lt;- ggplot(heatmap_data_n_long, aes(x = duration_group, y = customer_group, fill = n)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"blue\") +\n  labs(title = \"Fraud Reported = N\", x = \"Policy Hold Duration Group\", y = \"Months as Customer Group\") +\n  theme_minimal()\n\nlibrary(patchwork)\np1 + p2 + plot_layout(ncol = 1)\n\n\n\n\n\nThe two heatmaps provided visualize the frequency of fraud reports (yes or no) against two dimensions: the duration for which a policy has been held (Policy Hold Duration Group) and the number of months a customer has been grouped with a particular profile (Months as Customer Group). The ‘Policy Hold Duration Group’ is represented on the x-axis, with increasing intervals from left to right. The ‘Months as Customer Group’ is shown on the y-axis, also with increasing intervals moving up the axis. The intensity of the color in each cell of the heatmap represents the number of cases, with darker shades indicating a higher number of cases.\nFor the heatmap where fraud is reported (‘Y’), we observe:\nThere are several darker cells, indicating a higher concentration of fraud reports. This seems to occur across a variety of customer group durations and policy hold durations, suggesting that fraud is not confined to a specific duration of policy holding or customer grouping.\nThe highest concentrations of reported fraud (darkest red cells) are not isolated to the longest durations of policy holding or months as a customer, which may imply that the length of time a person has been a customer or held a policy is not a reliable indicator of fraudulent behavior.\nIn the heatmap where fraud is not reported (‘N’), we see:\nA generally uniform distribution of non-fraudulent cases across different durations of policy holding and customer group months. The shades are relatively lighter, indicating fewer cases per cell compared to the fraud-reported heatmap.\nThere are some slightly darker blue cells scattered throughout, but these do not show a clear pattern in relation to policy or customer duration groups.\nComparing the two heatmaps:\nThe heatmap for fraud-reported cases (‘Y’) has more variation in the number of cases across the cells, whereas the heatmap for non-fraud cases (‘N’) is more uniform. Neither heatmap shows a clear gradient or pattern that would indicate a trend, such as an increase in fraud reports with longer policy holding periods or months as a customer.\nFrom this analysis, it can be deduced that there is no strong visual correlation between the duration of policy holding or months as a customer with the likelihood of a fraud report being filed, as high frequencies of fraud reports are scattered across various groups. However, further statistical analysis would be needed to determine if there are significant patterns or correlations that are not immediately visible from the heatmap representation.\n\n\n3.3.2 Policy Design\n\n\nCode\ndata$incident_severity &lt;- factor(data$incident_severity, levels = c(\"Trivial Damage\", \"Minor Damage\", \"Major Damage\", \"Total Loss\"))\n\nlight_red &lt;- \"#FF9999\"  \nlight_blue &lt;- \"#9999FF\" \n\nggplot(data, aes(x = incident_severity, y = policy_deductable, fill = fraud_reported)) +\n  geom_violin() +\n  scale_fill_manual(values = c(\"Y\" = light_red, \"N\" = light_blue)) + \n  labs(title = \"Violin Plot of Policy Deductable by Incident Severity\",\n       x = \"Incident Severity\",\n       y = \"Policy Deductable\") +\n  theme_minimal()\n\n\n\n\n\nThe violin plot comparing the policy deductibles across different levels of incident severity, categorized by whether fraud was reported.\nA violin plot is similar to a box plot but also includes a kernel density estimation to show the distribution shape of the data. Wider sections of the violin plot represent a higher probability that members of the population will take on the given value; the slimmer sections represent a lower probability.\nfrom the plot:\nFor each incident severity category (Trivial Damage, Minor Damage, Major Damage, Total Loss), there are two distributions side by side — one for non-fraudulent claims (blue) and one for fraudulent claims (red).\nThe distributions for non-fraudulent claims tend to be more varied, with wider sections indicating a range of deductible amounts that are commonly chosen.\nThe fraudulent claims distributions appear narrower, suggesting that fraudulent claims are associated with a smaller range of deductible amounts. Interestingly, for ‘Trivial Damage’ and ‘Total Loss’, the median deductible amount for fraudulent claims is higher than for non-fraudulent claims.\nIn ‘Major Damage’, the fraudulent claims show a lower distribution of deductibles compared to non-fraudulent claims, indicating that lower deductibles are more common in fraudulent claims of this severity.\nThese patterns might suggest a relationship between the chosen policy deductible and the likelihood of a claim being fraudulent. For example, the higher median deductibles for fraudulent claims in the ‘Trivial Damage’ and ‘Total Loss’ categories might imply that those filing fraudulent claims in these categories are willing to pay a higher deductible, potentially to receive a larger claim payout.\nHowever, it’s important to note that the violin plot provides a visual estimation of the distributions and should be further investigated with statistical analysis to draw firm conclusions.\n\n\n3.3.3 PCA\n\n\nCode\nselected_data &lt;- data %&gt;% \n  select(\n    months_as_customer,\n    age,\n    policy_deductable,\n    policy_annual_premium,\n    capital_gains = `capital.gains`,\n    capital_loss = `capital.loss`,\n    incident_severity,\n    number_of_vehicles_involved,\n    bodily_injuries,\n    witnesses,\n    injury_claim,\n    property_claim,\n    vehicle_claim,\n    fraud_reported\n  ) %&gt;%\n  mutate(\n    incident_severity = case_when(\n      incident_severity == \"Trivial Damage\" ~ 0,\n      incident_severity == \"Minor Damage\"   ~ 1,\n      incident_severity == \"Major Damage\"   ~ 2,\n      incident_severity == \"Total Loss\"     ~ 3,\n      TRUE ~ NA_integer_\n    )\n  )\n\n\n\n\nCode\nselected_data_normalized &lt;- selected_data %&gt;%\n  mutate(across(where(is.numeric), ~scale(.) %&gt;% as.vector))\n\n\n\n\nCode\nlibrary(factoextra)\n\npca_result &lt;- prcomp(selected_data_normalized[,1:13], scale. = TRUE)\n\nvariables &lt;- rownames(pca_result$rotation)\ncolors &lt;- rainbow(length(variables)) \n\nfviz_pca_biplot(pca_result, \n                geom = c(\"point\", \"arrow\"),\n                geom.ind = \"point\", \n                alpha.ind = 0.5,\n                pointsize = 1,\n                repel = TRUE,\n                labelsize = 3,\n                col.ind = selected_data_normalized$fraud_reported)\n\n\n\n\n\nFrom this biplot, we can observe:\nThe observations (claims) are spread out across the first and second principal components, which account for 21.7% and 14.7% of the variance in the data, respectively.\nCertain features like ‘months_as_customer’ and ‘age’ seem to point in the same direction, suggesting that they might be correlated or change together. These features have a strong influence on the second principal component but less on the first.\nThe fraudulent claims (blue triangles) are dispersed throughout the plot but seem to have a slight concentration in the negative direction of the first principal component.\nFeatures such as ‘policy_annual_premium’, ‘capital_loss’, and ‘witnesses’ have a strong positive influence on the first principal component, indicating that these variables are significant in separating the claims along this axis.\nThere is no distinct separation between fraudulent and non-fraudulent claims, as indicated by the overlap of red circles and blue triangles. This suggests that, based on the PCA, the selected features do not create clear clusters or groupings that separate fraudulent from non-fraudulent claims.\nThe lack of clear separation might indicate that the features included in the PCA are not strong predictors of fraud on their own, or that fraud is a complex phenomenon that cannot be easily distinguished by these variables."
  }
]